{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcdf26",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data\n",
    "Load the trained model and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602aabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model = joblib.load('../models/disease_prediction_model.pkl')\n",
    "# \n",
    "# # Load test data\n",
    "# X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "# y_test = pd.read_csv('../data/processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf94b08",
   "metadata": {},
   "source": [
    "## 2. Generate Predictions\n",
    "Make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827be2c2",
   "metadata": {},
   "source": [
    "## 3. Confusion Matrix\n",
    "Visualize the confusion matrix to see prediction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# \n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../visualizations/confusion_matrix.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc25094",
   "metadata": {},
   "source": [
    "## 4. Classification Metrics\n",
    "Display detailed classification metrics for each disease class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# \n",
    "# # Save to file\n",
    "# with open('../results/classification_report.txt', 'w') as f:\n",
    "#     f.write(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c36bca",
   "metadata": {},
   "source": [
    "## 5. ROC Curve Analysis\n",
    "Plot ROC curves for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77156e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for multi-class (one-vs-rest approach)\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# \n",
    "# # Binarize the output\n",
    "# y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "# n_classes = y_test_bin.shape[1]\n",
    "# \n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for i in range(n_classes):\n",
    "#     fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "# \n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curves - Multi-class')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../visualizations/roc_curves.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b70742",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "Analyze which features are most important for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1affda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "# if hasattr(model, 'feature_importances_'):\n",
    "#     feature_importance = pd.DataFrame({\n",
    "#         'feature': X_test.columns,\n",
    "#         'importance': model.feature_importances_\n",
    "#     }).sort_values('importance', ascending=False)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.barh(feature_importance['feature'][:20], feature_importance['importance'][:20])\n",
    "#     plt.xlabel('Importance')\n",
    "#     plt.title('Top 20 Feature Importances')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('../visualizations/feature_importance.png', dpi=300)\n",
    "#     plt.show()\n",
    "#     \n",
    "#     # Save to CSV\n",
    "#     feature_importance.to_csv('../results/feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62442e80",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Model evaluation complete! Check the results and visualizations folders for outputs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
